# Bu modÃ¼l, kullanÄ±cÄ±dan gelen mesajlarÄ± iÅŸler, kural tabanlÄ± (rule-based) ve LLM yanÄ±tlarÄ±nÄ± birleÅŸtirerek
# nihai cevabÄ± Ã¼retir. Ä°nsan kaynaklarÄ± (Ä°K) konularÄ±nda Ã¶zel portal ipuÃ§larÄ± ekleyebilir, 
# oturum iÃ§i hafÄ±za ve konuÅŸma geÃ§miÅŸi yÃ¶netimi saÄŸlar.

import json
import re
import datetime
import random
from llm_client import query_llm
from stanza_utils import process_text
from rule_engine import RuleEngine
from collections import deque

PORTAL_HINTS = [
    "Detaylar iÃ§in Ä°K portalÄ±na [Portal Linki] Ã¼zerinden ulaÅŸabilirsiniz.",
    "Ä°K portalÄ± ([Portal Linki]) Ã¼zerinden kiÅŸisel kayÄ±tlarÄ±nÄ±zÄ± gÃ¶rÃ¼ntÃ¼leyebilirsiniz.",
    "HesabÄ±nÄ±zla Ä°K portalÄ±na [Portal Linki] yoluyla giriÅŸ yapÄ±p ilgili bilgileri kontrol edebilirsiniz.",
    "KÄ±sa yol: Ä°K portalÄ± > Profil > MaaÅŸ/Ä°zin bilgileri (eriÅŸim: [Portal Linki]).",
    "GÃ¼ncel bilgiler Ä°K portalÄ±nda yer alÄ±r; eriÅŸim iÃ§in: [Portal Linki].",
    "Ä°K sÃ¼reÃ§lerine dair adÄ±mlar iÃ§in Ä°K portalÄ±nÄ± kullanabilirsiniz: [Portal Linki].",
    "Ä°K portalÄ± Ã¼zerinden ( [Portal Linki] ) ilgili sayfaya giderek inceleyebilirsiniz.",
    "Kurumsal eriÅŸim: Ä°K portalÄ± â€” [Portal Linki]."
]

def load_not_allowed_topics(path="filters/not_allowed_topics.txt"):  # YasaklÄ± konularÄ± dosyadan yÃ¼kler
    try:
        with open(path, "r", encoding="utf-8") as f:
            return [line.strip().lower() for line in f if line.strip()]
    except FileNotFoundError:
        # Dosya henÃ¼z mevcut deÄŸilse varsayÄ±lan olarak boÅŸ bir liste kullan
        return []

def build_not_allowed_regex(words):  # YasaklÄ± kelimeler iÃ§in regex oluÅŸturur
    if not words:
        return None
    escaped = [re.escape(w) for w in words]
    # Kelimenin tamamÄ±nÄ±n eÅŸleÅŸmesini saÄŸlamak iÃ§in word-boundary kullanÄ±lÄ±r
    pattern = r"\b(?:" + "|".join(escaped) + r")\b"
    return re.compile(pattern, flags=re.IGNORECASE)

NOT_ALLOWED_TOPICS = load_not_allowed_topics()
NOT_ALLOWED_RE = build_not_allowed_regex(NOT_ALLOWED_TOPICS)

GREETING_WORDS = ["selam", "merhaba", "naber", "nasÄ±lsÄ±n", "gÃ¼naydÄ±n", "iyi akÅŸamlar", "iyi geceler"]

SESSION_CONTEXT = deque(maxlen=20)  # Son 20 konuÅŸma tutulur: {"role": "user"|"bot", "text": str}
SESSION_FACTS = {}  # Oturumda hatÄ±rlanan basit anahtar-deÄŸer bilgileri, Ã¶r: {"user_name": "Eren", "bot_name": "Gemma"}

# KullanÄ±cÄ± adÄ±nÄ± AYARLAMA: "benim adÄ±m X"
USER_NAME_SET_PAT = re.compile(r"\bbenim ad[Ä±i]m\s+([A-Za-zÃ‡ÄÄ°Ã–ÅÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)\b", re.IGNORECASE)
# Bot adÄ±nÄ± AYARLAMA: "senin adÄ±n X"
BOT_NAME_SET_PAT = re.compile(r"\bsenin ad[Ä±i]n\s+([A-Za-zÃ‡ÄÄ°Ã–ÅÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)\b", re.IGNORECASE)
# KullanÄ±cÄ± adÄ±nÄ± SORMA: "adÄ±mÄ± hatÄ±rlÄ±yor musun?", "adÄ±m neydi?", "benim adÄ±m ne?"
USER_NAME_ASK_PAT = re.compile(
    r"\bad[Ä±i]m[Ä±i]?\s+(?:hat[Ä±i]rl[Ä±i]yor musun|neydi)\b|\bbenim ad[Ä±i]m ne\b",
    re.IGNORECASE,
)
# Bot adÄ±nÄ± SORMA: "senin adÄ±n ne?", "senin adÄ±n neydi?", "kendi adÄ±nÄ± hatÄ±rlÄ±yor musun?"
BOT_NAME_ASK_PAT = re.compile(
    r"\bsenin ad[Ä±i]n\s+(?:ne|neydi|nedir|var mÄ±)\b|\bkendi ad[Ä±i]n[Ä±i]?\s+hat[Ä±i]rl[Ä±i]yor musun\b",
    re.IGNORECASE,
)

def update_facts_from_user(text: str):  # KullanÄ±cÄ±dan alÄ±nan bilgileri hafÄ±zaya kaydeder
    if not text:
        return
    # KullanÄ±cÄ± kendi adÄ±nÄ± sÃ¶yledi
    m_user = USER_NAME_SET_PAT.search(text)
    if m_user:
        name_val = m_user.group(1).strip()
        SESSION_FACTS["user_name"] = name_val
        SESSION_FACTS["name"] = name_val  # geriye dÃ¶nÃ¼k uyumluluk
        return

    # KullanÄ±cÄ± botun adÄ±nÄ± belirtti
    m_bot = BOT_NAME_SET_PAT.search(text)
    if m_bot:
        SESSION_FACTS["bot_name"] = m_bot.group(1).strip()
        return

def answer_if_memory_query(text: str):  # KullanÄ±cÄ± hafÄ±zadaki bilgileri sorarsa yanÄ±tlar
    if not text:
        return None

    # KullanÄ±cÄ±nÄ±n adÄ±nÄ± soruyor mu?
    if USER_NAME_ASK_PAT.search(text):
        name = SESSION_FACTS.get("user_name") or SESSION_FACTS.get("name")
        return name if name else "HenÃ¼z adÄ±nÄ± kaydetmemiÅŸim gibi gÃ¶rÃ¼nÃ¼yor. Ä°stersen 'Benim adÄ±m X' diyebilirsin."

    # Botun adÄ±nÄ± soruyor mu?
    if BOT_NAME_ASK_PAT.search(text):
        bot_name = SESSION_FACTS.get("bot_name")
        return bot_name if bot_name else "HenÃ¼z bir adÄ±m yok. Ä°stersen 'Senin adÄ±n X' diyerek belirleyebilirsin."

    return None

def reset_session_context():  # Oturumdaki geÃ§miÅŸi ve bilgileri sÄ±fÄ±rlar
  SESSION_CONTEXT.clear()
  SESSION_FACTS.clear()

def render_context_snippet(max_chars: int = 1200) -> str:  # Son konuÅŸmalarÄ± kÄ±sa bir Ã¶zet olarak dÃ¶ndÃ¼rÃ¼r
  # KÄ±sa bir konuÅŸma dÃ¶kÃ¼mÃ¼ oluÅŸturur: "K: ...\nB: ...\n"
  parts = []
  for item in SESSION_CONTEXT:
    prefix = "K:" if item["role"] == "user" else "B:"
    parts.append(f"{prefix} {item['text']}")
  text = "\n".join(parts)
  return text[-max_chars:] if len(text) > max_chars else text

def is_noise_text(t: str) -> bool:  # Girilen metnin anlamsÄ±z olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    s = (t or "").strip()
    if len(s) <= 1:
        return True
    # Sezgisel: Harf olmayan karakterler %60'tan fazlaysa veya hiÃ§ sesli harf yoksa anlamsÄ±z kabul edilir
    letters = sum(1 for ch in s if ch.isalpha())
    non_letters = len(s) - letters
    if len(s) > 0 and non_letters / len(s) > 0.6:
        return True
    vowels = set("aeÄ±ioÃ¶uÃ¼AEIÄ°OÃ–UÃœ")
    if not any(ch in vowels for ch in s):
        return True
    return False

rule_engine = RuleEngine()

def log_chat(user_input, response, response_type, intent=None):  # Sohbet geÃ§miÅŸini dosyaya kaydeder
    log_entry = {
        "timestamp": datetime.datetime.now().isoformat(),
        "user_input": user_input,
        "response": response,
        "intent": intent,
        "type": response_type
    }
    with open("chat_history.json", "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

TIME_RE = re.compile(r"\b\d{1,2}:\d{2}\b") #saat redexi
NUM_RE = re.compile(r"\b\d+[\.,]?\d*\b") #sayÄ± redexi

PORTAL_INTENTS = {
    "maas_bilgisi",           # MaaÅŸÄ±mÄ± nereden Ã¶ÄŸrenebilirim?
    "sigorta_baslangic",     # Sigortam ne zaman baÅŸlar?
    "prim_odeme",            # Prim Ã¶demesi alÄ±yor muyum?
    "yemek_karti_yukleme",   # Yemek kartÄ± ne zaman yÃ¼klenir?
}
PORTAL_Q_RE = re.compile(
    r"(maaÅŸ(?:Ä±m)?\s+nereden\s+Ã¶ÄŸrenebilirim|sigortam\s+ne\s+zaman\s+baÅŸlar|prim\s+(?:Ã¶demesi\s+)?al[Ä±i]yor\s+muyum|yemek\s+kart[Ä±i]\s+ne\s+zaman\s+y[Ã¼u]klenir)",
    re.IGNORECASE,
)

def contains_key_facts(text: str, ref: str) -> bool:  # YanÄ±tta Ã¶nemli sayÄ±sal/tarihsel bilgilerin korunup korunmadÄ±ÄŸÄ±nÄ± kontrol eder
    if not text or not ref:
        return False
    times = set(TIME_RE.findall(ref))
    nums = set(NUM_RE.findall(ref))

    t = text
    r = ref

    if times:
        # Referanstaki tÃ¼m saat ifadeleri yanÄ±tta da bulunmalÄ±
        if not all(tk in t for tk in times):
            return False
    if nums:
        # Referanstaki en az bir sayÄ±sal ifade yanÄ±tta da bulunmalÄ±
        if not any(n in t for n in nums):
            return False

    if times or nums:
        return True

    # SayÄ± veya saat yoksa: normalize edip gevÅŸek iÃ§erme kontrolÃ¼ yapÄ±lÄ±r
    def _norm(s: str) -> str:
        s = s.lower()
        s = re.sub(r"\s+", " ", s).strip()
        return s

    tn = _norm(t)
    rn = _norm(r)

    return (rn in tn) or (tn in rn)

def format_final_response(rule_response, llm_response, intent=None, prefer_llm_for_rule: bool = False):  # Son cevabÄ± kural ve LLM yanÄ±tlarÄ±nÄ± birleÅŸtirerek oluÅŸturur
    """
    Rule-based ve LLM cevabÄ±nÄ± ortak bir formatta birleÅŸtirir.
    VarsayÄ±lan: KuralÄ± esas al. 
    - prefer_llm_for_rule=True ise: kural + LLM birleÅŸik "hybrid" yanÄ±t Ã¼ret.
    - Aksi halde: LLM Ã§Ä±ktÄ±sÄ± kuralÄ±n sayÄ±sal/tarih/saat bilgilerini KORUYORSA LLM gÃ¶ster; yoksa kural gÃ¶ster.
    """
    rule_response = (rule_response or "").strip()
    llm_response = (llm_response or "").strip()

    def _norm(s: str) -> str:
        return re.sub(r"\s+", " ", (s or "").strip().lower())

    source = "rule_based"
    if rule_response:
        if llm_response:
            if prefer_llm_for_rule:
                rr_n = _norm(rule_response)
                llm_n = _norm(llm_response)
                if rr_n in llm_n:
                    final = llm_response
                elif llm_n in rr_n:
                    final = rule_response
                else:
                    final = f"{rule_response} {llm_response}"
                source = "hybrid"
            else:
                if contains_key_facts(llm_response, rule_response):
                    final = llm_response
                    source = "llm"
                else:
                    final = rule_response
                    source = "rule_based"
        else:
            final = rule_response
            source = "rule_based"
    else:
        final = llm_response or "Cevap Ã¼retilemedi."
        source = "llm" if llm_response else "rule_based"

    return {
        "rule_based": rule_response,
        "llm": llm_response,
        "final_answer": final,
        "intent": intent,
        "source": source,
    }

def process_input_step(context):  # KullanÄ±cÄ± girdisini iÅŸler ve Ã¶niÅŸleme yapar
    user_input = context["input"]
    update_facts_from_user(user_input)
    context["lemmas"] = process_text(user_input)
    return context

def rule_match_step(context):  # Kurallara gÃ¶re eÅŸleÅŸen bir yanÄ±t olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    result = rule_engine.match_rule(context["input"])
    if result:
        context["rule_response"] = result["rule_based"]
        context["intent"] = result.get("intent")
        context["tags"] = result.get("tags")
    else:
        context["rule_response"] = None
        context["intent"] = None
    return context

def llm_query_step(context):  # LLM'den cevap almak iÃ§in gerekli adÄ±mlarÄ± uygular
    user_input = context["input"].lower()
    portal_hint = random.choice(PORTAL_HINTS)

    # Filtreleme iÃ§in kÃ¼Ã§Ã¼k harfe Ã§evrilmiÅŸ metin ve lemmalar birleÅŸtirilir
    lemmas = context.get("lemmas") or []
    combined_text = (user_input + " " + " ".join(lemmas)).lower()

    # KullanÄ±cÄ± ad/isim belirliyorsa doÄŸrudan yanÄ±tla (LLM atlanÄ±r)
    set_user = USER_NAME_SET_PAT.search(context["input"])
    set_bot = BOT_NAME_SET_PAT.search(context["input"])
    if set_user or set_bot:
        uname = SESSION_FACTS.get("user_name")
        bname = SESSION_FACTS.get("bot_name")
        if set_user and set_bot and uname and bname:
            context["llm_response"] = f"Tamam, senin adÄ±n {uname}, benim adÄ±m {bname}."
            return context
        if set_user and uname:
            context["llm_response"] = f"Memnun oldum {uname}!"
            return context
        if set_bot and bname:
            context["llm_response"] = f"Tamam, adÄ±m {bname}."
            return context

    # GÃ¼rÃ¼ltÃ¼ korumasÄ±: Girdi anlamsÄ±zsa, geÃ§miÅŸ kullanmadan kibarca yanÄ±t ver
    if is_noise_text(user_input):
        context["llm_response"] = "AnladÄ±m, ama mesajÄ±n pek anlaÅŸÄ±lÄ±r deÄŸil. Biraz daha detay verebilir misin?"
        return context

    # KullanÄ±cÄ± oturum bilgisinden yanÄ±tlanabilecek bir ÅŸey soruyorsa, doÄŸrudan cevapla
    mem_ans = answer_if_memory_query(context["input"])
    if mem_ans is not None:
        context["llm_response"] = mem_ans
        return context

    convo_snippet = render_context_snippet()
    has_history = bool(convo_snippet.strip())

    # Selamlama kÄ±sayolu: Portal ipucu olmadan kibarca yanÄ±tla
    if any(w in combined_text for w in GREETING_WORDS):
        prompt = (
            "SÄ°STEM TALÄ°MATI:\n"
            "- Sadece kullanÄ±cÄ±ya kÄ±sa bir selamlama ve yardÄ±m teklifi yaz. Meta yorum yapma.\n\n"
            f"KULLANICI MESAJI:\n{user_input}\n"
        )
        context["llm_response"] = query_llm(prompt)
        return context

    # YasaklÄ± kelime filtresi: Tam kelime olarak geÃ§en yasaklÄ± bir ifade varsa engelle
    if NOT_ALLOWED_RE and NOT_ALLOWED_RE.search(combined_text):
        context["llm_response"] = "Bu konu hakkÄ±nda yardÄ±mcÄ± olamÄ±yorum."
        return context

    try:
        if context.get("rule_response"):
            # Sadece bazÄ± Ä°K sorularÄ± iÃ§in portal ipucu + LLM ile yeniden ifade eklenir
            want_portal = (context.get("intent") in PORTAL_INTENTS) or bool(PORTAL_Q_RE.search(context["input"]))
            context["prefer_llm_for_rule"] = bool(want_portal)

            if want_portal:
                prompt = (
                    "SÄ°STEM TALÄ°MATI:\n"
                    "- KURAL CEVABI temel alÄ±nacak, metnin Ã¶zÃ¼nÃ¼ ve rakamsal/tarih/saat bilgilerini AYNEN koru.\n"
                    "- YANITINI yalnÄ±zca 'KULLANICI MESAJI'na ver; geÃ§miÅŸi sadece baÄŸlam olarak kullan.\n"
                    "- KÄ±sa ve net TÃ¼rkÃ§e yaz. Gerekirse maddeler kullan.\n"
                    "- Uydurma veya kural dÄ±ÅŸÄ± bilgi ekleme. Belirsizse dÃ¼rÃ¼stÃ§e belirt.\n"
                    "- AÅŸaÄŸÄ±daki ipucunu baÄŸlama uygun ÅŸekilde metne yedir (aynen kopyalamak zorunda deÄŸilsin):\n"
                    f"  > {portal_hint}\n\n"
                    + (f"Ã–NCEKÄ° KONUÅMA (son 20):\n{convo_snippet}\n\n" if has_history else "")
                    + f"KULLANICI MESAJI:\n{user_input}\n\n"
                    + f"KURAL CEVABI:\n{context['rule_response']}\n"
                )
                context["llm_response"] = query_llm(prompt)
            else:
                # DiÄŸer kural tabanlÄ± eÅŸleÅŸmelerde portal ipucu ve LLM olmadan kural yanÄ±tÄ± dÃ¶ndÃ¼rÃ¼lÃ¼r
                context["llm_response"] = ""
            return context
        else:
            prompt = (
                "SÄ°STEM TALÄ°MATI:\n"
                "- YANITINI DAÄ°MA yalnÄ±zca 'KULLANICI MESAJI'na ver; geÃ§miÅŸi sadece baÄŸlam olarak kullan.\n"
                "- KÄ±sa ve net TÃ¼rkÃ§e yaz. Gerekirse maddeler kullan.\n"
                "- KullanÄ±cÄ±nÄ±n adÄ±nÄ± sadece doÄŸrudan sorarsa belirt; aksi halde ad veya tek kelimeyle yanÄ±t verme.\n"
                "- Uydurma bilgi verme; belirsizse aÃ§Ä±kÃ§a sÃ¶yle.\n"
                + (f"Ã–NCEKÄ° KONUÅMA (son 20):\n{convo_snippet}\n\n" if has_history else "")
                + f"KULLANICI MESAJI:\n{user_input}\n"
            )
            context["llm_response"] = query_llm(prompt)
    except Exception as e:
        context["llm_response"] = f"[LLM HATA] {str(e)}"
        log_chat(user_input, context["llm_response"], "llm-error", intent=context.get("intent"))
    return context

def format_response_step(context):  # Nihai cevabÄ± oluÅŸturur ve oturum geÃ§miÅŸine ekler
    rule_response = context.get("rule_response")
    llm_response = context.get("llm_response")
    context["result"] = format_final_response(
        rule_response,
        llm_response,
        intent=context.get("intent"),
        prefer_llm_for_rule=bool(context.get("prefer_llm_for_rule"))
    )
    # Bu turu geÃ§ici belleÄŸe kaydet (son 20 tutulur)
    try:
        SESSION_CONTEXT.append({"role": "user", "text": context.get("input", "")})
        SESSION_CONTEXT.append({"role": "bot", "text": context["result"].get("final_answer", "")})
    except Exception:
        pass
    # KaynaÄŸÄ± artÄ±k format_final_response belirliyor; burada tekrar yazmÄ±yoruz.
    return context

def run_pipeline(user_input):  # TÃ¼m sohbet iÅŸleme adÄ±mlarÄ±nÄ± sÄ±ralÄ± ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±r
    context = {"input": user_input}
    try:
        steps = [process_input_step, rule_match_step, llm_query_step, format_response_step]
        for step in steps:
            context = step(context)
        return context["result"]
    except Exception as e:
        error_message = f"[HATA] NLP iÅŸleme baÅŸarÄ±sÄ±z: {str(e)}"
        log_chat(user_input, error_message, "error")
        return {
            "rule_based": None,
            "llm": None,
            "final_answer": error_message
        }

def _search_chat_history_internal(keyword=None, date_str=None):  # Sohbet geÃ§miÅŸinde anahtar kelime ve tarihe gÃ¶re arama yapar
    try:
        with open("chat_history.json", "r", encoding="utf-8") as f:
            results = []
            for line in f:
                entry = json.loads(line)

                matches_keyword = True
                matches_date = True

                if keyword:
                    matches_keyword = re.search(keyword, entry["user_input"], re.IGNORECASE)

                if date_str:
                    try:
                        parsed_date = datetime.datetime.strptime(date_str + " 2025", "%d %B %Y").date()
                        entry_date = datetime.datetime.fromisoformat(entry["timestamp"]).date()
                        matches_date = (parsed_date == entry_date)
                    except:
                        continue

                if matches_keyword and matches_date:
                    results.append(entry)
        return results
    except FileNotFoundError:
        return []

def get_chat_history(keyword=None, date_str=None) -> list:  # Sohbet geÃ§miÅŸini dÄ±ÅŸarÄ±ya sunar
    return _search_chat_history_internal(keyword, date_str)

def get_response(user_input: str) -> dict:  # KullanÄ±cÄ±dan gelen mesaja karÅŸÄ±lÄ±k yanÄ±t Ã¼retir
    return run_pipeline(user_input)

def session_reset():  # Oturumu sÄ±fÄ±rlar
    reset_session_context()
    return {"ok": True}

if __name__ == "__main__":
    print("Chatbot'a hoÅŸ geldiniz! Ã‡Ä±kmak iÃ§in 'q' yazÄ±n.\n")
    while True:
        user_input = input("Sen: ")
        if user_input.lower() == 'q':
            break
        if user_input.lower().startswith("geÃ§miÅŸ"):
            parts = user_input.split()
            keyword = None
            date = None

            if len(parts) >= 2:
                keyword = parts[1]
            if len(parts) >= 3:
                date = parts[2] + " " + parts[3] if len(parts) >= 4 else parts[2]

            results = _search_chat_history_internal(keyword, date)
            if not results:
                print("âŒ HiÃ§bir eÅŸleÅŸme bulunamadÄ±.")
            else:
                print(f"ğŸ” {len(results)} eÅŸleÅŸme bulundu:\n")
                for r in results:
                    print(f"ğŸ•“ {r['timestamp']}")
                    print(f"ğŸ‘¤ {r['user_input']}")
                    print(f"ğŸ¤– ({r['type']}): {r['response']}\n")
            continue
        response = run_pipeline(user_input)
        log_chat(user_input, response["final_answer"], response_type=response.get("source"), intent=response.get("intent"))
        print("Bot:", response["final_answer"])